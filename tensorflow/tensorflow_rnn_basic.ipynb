{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'tensorflow_core._api.v2.version' from '/home/sun/miniconda2/envs/py37/lib/python3.7/site-packages/tensorflow_core/_api/v2/version/__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import tensorflow as tf\n",
    "print(tf.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "(2, 2)\n"
     ]
    }
   ],
   "source": [
    "string = tf.Variable(\"this is a string\", tf.string) \n",
    "number = tf.Variable(324, tf.int16)\n",
    "floating = tf.Variable(3.567, tf.float64)\n",
    "rank2_tensor = tf.Variable([[1, 2], [3, 4]], tf.int16)\n",
    "\n",
    "print(tf.rank(rank2_tensor))\n",
    "print(rank2_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[1. 1. 1.]\n",
      "  [1. 1. 1.]]], shape=(1, 2, 3), dtype=float32)\n",
      "\n",
      "tf.Tensor(\n",
      "[[1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tensor1 = tf.ones([1,2,3])\n",
    "print(tensor1)\n",
    "print()\n",
    "tensor2 = tf.reshape(tensor1, [3, -1])\n",
    "print(tensor2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression - Titanic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dftrain = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv') # training data\n",
    "dfeval = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv') # testing data\n",
    "y_train = dftrain.pop('survived')\n",
    "y_eval = dfeval.pop('survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
       "0    male  22.0                   1      0   7.2500  Third  unknown   \n",
       "1  female  38.0                   1      0  71.2833  First        C   \n",
       "2  female  26.0                   0      0   7.9250  Third  unknown   \n",
       "3  female  35.0                   1      0  53.1000  First        C   \n",
       "4    male  28.0                   0      0   8.4583  Third  unknown   \n",
       "\n",
       "   embark_town alone  \n",
       "0  Southampton     n  \n",
       "1    Cherbourg     n  \n",
       "2  Southampton     y  \n",
       "3  Southampton     n  \n",
       "4   Queenstown     y  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VocabularyListCategoricalColumn(key='sex', vocabulary_list=('male', 'female'), dtype=tf.string, default_value=-1, num_oov_buckets=0)\n"
     ]
    }
   ],
   "source": [
    "CATEGORICAL_COLUMNS = ['sex', 'n_siblings_spouses', 'parch', 'class', 'deck','embark_town', 'alone']\n",
    "NUMERIC_COLUMNS = ['age', 'fare']\n",
    "\n",
    "feature_columns = []\n",
    "for feature_name in CATEGORICAL_COLUMNS:\n",
    "    vocabulary = dftrain[feature_name].unique()  # gets a list of all unique values from given feature column\n",
    "    feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary))\n",
    "\n",
    "for feature_name in NUMERIC_COLUMNS:\n",
    "    feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32))\n",
    "\n",
    "print(feature_columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=32):\n",
    "    \n",
    "    def input_function():\n",
    "        ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))\n",
    "        \n",
    "        if shuffle:\n",
    "            ds = ds.shuffle(1000) \n",
    "        \n",
    "        ds = ds.batch(batch_size).repeat(num_epochs)\n",
    "        return ds \n",
    "    \n",
    "    return input_function\n",
    "\n",
    "train_input_fn = make_input_fn(dftrain, y_train)\n",
    "eval_input_fn = make_input_fn(dfeval, y_eval, num_epochs=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75757575\n"
     ]
    }
   ],
   "source": [
    "linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns)\n",
    "linear_est.train(train_input_fn)\n",
    "result = linear_est.evaluate(eval_input_fn)\n",
    "\n",
    "clear_output()  \n",
    "print(result['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fb5d81b5810>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_dicts = list(linear_est.predict(eval_input_fn))\n",
    "probs = pd.Series([pred['probabilities'][1] for pred in pred_dicts])\n",
    "\n",
    "clear_output()  \n",
    "probs.plot(kind='hist', bins=20, title='predicted probabilities')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification - Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n",
    "SPECIES = ['Setosa', 'Versicolor', 'Virginica']\n",
    "\n",
    "train_path = tf.keras.utils.get_file(\n",
    "    \"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
    "test_path = tf.keras.utils.get_file(\n",
    "    \"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n",
    "\n",
    "train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth\n",
       "0          6.4         2.8          5.6         2.2\n",
       "1          5.0         2.3          3.3         1.0\n",
       "2          4.9         2.5          4.5         1.7\n",
       "3          4.9         3.1          1.5         0.1\n",
       "4          5.7         3.8          1.7         0.3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = train.pop('Species')\n",
    "test_y = test.pop('Species')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(features, labels, training=True, batch_size=256):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(1000).repeat()\n",
    "    \n",
    "    return dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n"
     ]
    }
   ],
   "source": [
    "my_feature_columns = []\n",
    "for key in train.keys():\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
    "\n",
    "print(my_feature_columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set accuracy: 0.933\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build a DNN with 2 hidden layers with 30 and 10 hidden nodes each.\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=my_feature_columns,\n",
    "    hidden_units=[30, 10],\n",
    "    n_classes=3)\n",
    "\n",
    "classifier.train(\n",
    "    input_fn=lambda: input_fn(train, train_y, training=True),\n",
    "    steps=5000)\n",
    "\n",
    "eval_result = classifier.evaluate(\n",
    "    input_fn=lambda: input_fn(test, test_y, training=False))\n",
    "\n",
    "clear_output()\n",
    "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks - fashion MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(train_images[0])\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.4962 - accuracy: 0.8252\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3746 - accuracy: 0.8652\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.3352 - accuracy: 0.8781\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 3s 51us/sample - loss: 0.3112 - accuracy: 0.8854\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.2945 - accuracy: 0.8917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb5f46be190>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),  # input layer (1)\n",
    "    keras.layers.Dense(128, activation='relu'),  # hidden layer (2)\n",
    "    keras.layers.Dense(10, activation='softmax') # output layer (3)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/1 - 0s - loss: 0.2737 - accuracy: 0.8770\n",
      "Test accuracy: 0.877\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2) \n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN - Sentiment analysis with IMDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 88584\n",
    "MAXLEN = 250\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words = VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = sequence.pad_sequences(train_data, MAXLEN)\n",
    "test_data = sequence.pad_sequences(test_data, MAXLEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 32)          2834688   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,843,041\n",
      "Trainable params: 2,843,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(VOCAB_SIZE, 32),\n",
    "    tf.keras.layers.LSTM(32),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "20000/20000 [==============================] - 13s 649us/sample - loss: 0.4235 - acc: 0.8053 - val_loss: 0.3402 - val_acc: 0.8556\n",
      "25000/1 - 7s - loss: 0.3261 - acc: 0.8438\n",
      "[0.36459608827590945, 0.8438]\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=['acc'])\n",
    "model.fit(train_data, train_labels, epochs=1, validation_split=0.2)\n",
    "\n",
    "results = model.evaluate(test_data, test_labels, verbose=2)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = imdb.get_word_index()\n",
    "reverse_word_index = {value: key for (key, value) in word_index.items()}\n",
    "\n",
    "def encode_text(text):\n",
    "    tokens = keras.preprocessing.text.text_to_word_sequence(text)\n",
    "    tokens = [word_index[word] if word in word_index else 0 for word in tokens]\n",
    "    return sequence.pad_sequences([tokens], MAXLEN)[0]\n",
    "\n",
    "def decode_integers(integers):\n",
    "    PAD = 0\n",
    "    text = \"\"\n",
    "    for num in integers:\n",
    "        if num != PAD:\n",
    "            text += reverse_word_index[num] + \" \"\n",
    "    return text[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 12  17  13  40 477  35 477]\n",
      "that movie was just amazing so amazing\n"
     ]
    }
   ],
   "source": [
    "text = \"that movie was just amazing, so amazing\"\n",
    "encoded = encode_text(text)\n",
    "\n",
    "print(encoded[-7:]) # ignore the pads\n",
    "print(decode_integers(encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.79766613]\n",
      "[0.21395327]\n"
     ]
    }
   ],
   "source": [
    "def predict(text):\n",
    "    encoded_text = encode_text(text)\n",
    "    pred = np.zeros((1,250))\n",
    "    pred[0] = encoded_text\n",
    "    result = model.predict(pred) \n",
    "    print(result[0])\n",
    "\n",
    "positive_review = \"That movie was! really loved it and would great watch it again because it was amazingly great\"\n",
    "predict(positive_review)\n",
    "\n",
    "negative_review = \"that movie really sucked. I hated it and wouldn't watch it again. Was one of the worst things I've ever watched\"\n",
    "predict(negative_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN - Shakespeare play generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 1115394 characters\n"
     ]
    }
   ],
   "source": [
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "print ('Length of text: {} characters'.format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(set(text))\n",
    "\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "def text_to_int(text):\n",
    "    return np.array([char2idx[c] for c in text])\n",
    "\n",
    "def int_to_text(ints):\n",
    "    try:\n",
    "        ints = ints.numpy()\n",
    "    except:\n",
    "        pass\n",
    "    return ''.join(idx2char[ints])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen\n",
      "[18 47 56 57 58  1 15 47 58 47 64 43 52]\n",
      "First Citizen\n"
     ]
    }
   ],
   "source": [
    "text_as_int = text_to_int(text)\n",
    "\n",
    "print(text[:13])\n",
    "print(text_as_int[:13])\n",
    "print(int_to_text(text_as_int[:13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 100  # length of sequence for a training example\n",
    "examples_per_epoch = len(text) // (seq_length+1)\n",
    "\n",
    "def split_input_target(chunk):  # for the example: hello\n",
    "    input_text = chunk[:-1]  # hell\n",
    "    target_text = chunk[1:]  # ello\n",
    "    return input_text, target_text  # hell, ello\n",
    "\n",
    "\n",
    "# Create training examples and targets\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT\n",
      "\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n",
      "\n",
      "OUTPUT\n",
      "\n",
      "irst Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You \n"
     ]
    }
   ],
   "source": [
    "for x, y in dataset.take(1):\n",
    "    print(\"INPUT\\n\")\n",
    "    print(int_to_text(x))\n",
    "    print(\"\\nOUTPUT\\n\")\n",
    "    print(int_to_text(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "VOCAB_SIZE = len(vocab)  # vocab is number of unique characters\n",
    "EMBEDDING_DIM = 256\n",
    "RNN_UNITS = 1024\n",
    "\n",
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None]),\n",
    "        tf.keras.layers.LSTM(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.Dense(vocab_size)])\n",
    "    return model\n",
    "\n",
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (64, None, 256)           16640     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (64, None, 1024)          5246976   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (64, None, 65)            66625     \n",
      "=================================================================\n",
      "Total params: 5,330,241\n",
      "Trainable params: 5,330,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(VOCAB_SIZE,EMBEDDING_DIM, RNN_UNITS, BATCH_SIZE)\n",
    "model.compile(optimizer='adam', loss=loss)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "172/172 [==============================] - 18s 103ms/step - loss: 2.5625\n",
      "Epoch 2/2\n",
      "172/172 [==============================] - 16s 96ms/step - loss: 1.8689\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)\n",
    "\n",
    "data = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "history = model.fit(data, epochs=2, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for prediction with arbitrary input length\n",
    "model = build_model(VOCAB_SIZE, EMBEDDING_DIM, RNN_UNITS, batch_size=1)\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "    # Evaluation step (generating text using the learned model)\n",
    "\n",
    "    # Number of characters to generate\n",
    "    num_generate = 800\n",
    "\n",
    "    # Converting our start string to numbers (vectorizing)\n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    # Empty string to store our results\n",
    "    text_generated = []\n",
    "\n",
    "    # Low temperatures results in more predictable text.\n",
    "    # Higher temperatures results in more surprising text.\n",
    "    # Experiment to find the best setting.\n",
    "    temperature = 1.0\n",
    "\n",
    "    # Here batch size == 1\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        # remove the batch dimension\n",
    "\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "        # using a categorical distribution to predict the character returned by the model\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "        # We pass the predicted character as the next input to the model\n",
    "        # along with the previous hidden state\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "    return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type a starting string: All:\n",
      "All: \n",
      "HoRKZABISA:\n",
      "The chermth.\n",
      "Thit fells o hear in chill if hor\n",
      "Where alt there an theirthel sreming,\n",
      "The me'd and not thine your ipprarceare\n",
      "And cricedon on actuack yout Lain never\n",
      "On yourrend her will sulfortious!\n",
      "Which notlan ent my from go to a cerele:\n",
      "Be, getless and that he stry prech o'e.\n",
      "Becense poty and dupen ut, in out well fie, I make how batce,\n",
      "Ih he repslimatees in chardain and gon'd no more\n",
      "Of thou shold before thas both loth.\n",
      "\n",
      "POONONENO:\n",
      "Than!\n",
      "Do, I'll tall Pefull frim,\n",
      "I will have den your forturead, oe no common'e.\n",
      "He lateenul I thank,\n",
      "That to my hivene,\n",
      "And sinrow not. What, 'for of the bonesine\n",
      "Dood good me hame ropsow and canid it in thou:\n",
      "Ind good the Laye, say; sit!\n",
      "Have thy fairt wonimes 'To to Hergon of!\n",
      "\n",
      "WhAWISG HARCIO:\n",
      "De may vellown my higher enely.\n",
      "\n",
      "CEMILEN-O:\n",
      "Whyo\n"
     ]
    }
   ],
   "source": [
    "inp = input(\"Type a starting string: \")\n",
    "print(generate_text(model, inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
